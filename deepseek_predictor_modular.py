"""
DeepSeekæ¨¡å‹å‘å¸ƒé¢„æµ‹å™¨ - æ¨¡å—åŒ–ç‰ˆæœ¬
æ•´åˆæ‰€æœ‰ç‹¬ç«‹çš„é¢„æµ‹æ–¹æ³•ï¼Œæä¾›ç»Ÿä¸€çš„é¢„æµ‹æ¥å£
"""

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from typing import Dict, List

# å¯¼å…¥æ‰€æœ‰é¢„æµ‹å™¨
from models.linear_models import create_linear_predictor, create_ridge_predictor, create_lasso_predictor
from models.time_series import ARIMAPredictor, ExponentialSmoothingPredictor, SeasonalPredictor
from models.ensemble_models import RandomForestPredictor, GradientBoostingPredictor, XGBoostPredictor, SVRPredictor
from models.interval_based import (
    create_mean_interval_predictor, create_median_interval_predictor,
    create_recent_interval_predictor, create_adaptive_interval_predictor,
    create_weighted_interval_predictor
)
# æ’é™¤æ·±åº¦å­¦ä¹ ç®—æ³• - æ³¨é‡Šæ‰è¿™è¡Œ
# from models.neural_networks import MLPPredictor, LSTMPredictor
from models.statistical import TrendAnalysisPredictor, SeasonalDecomposePredictor, StatisticalPredictor


class DeepSeekPredictorModular:
    """æ¨¡å—åŒ–DeepSeeké¢„æµ‹å™¨"""
    
    def __init__(self):
        # åŸå§‹æ•°æ®
        self.data = {
            'version': [
                'DeepSeek Coder', 'DeepSeek-LLM', 'DeepSeek-V2 (Apr)',
                'DeepSeek-Coder V2 (Jun)', 'DeepSeek-V2 (Jun)', 'DeepSeek-Coder V2 (Jul)',
                'DeepSeek-V2.5 (Sep)', 'DeepSeek-V3', 'DeepSeek-V2.5 (Dec)',
                'DeepSeek-R1', 'DeepSeek-V3-0324', 'DeepSeek-R1-0528'
            ],
            'date': [
                '2023-11-02', '2023-11-29', '2024-04-28', '2024-06-14',
                '2024-06-28', '2024-07-24', '2024-09-05', '2024-12-25',
                '2024-12-10', '2025-01-20', '2025-03-24', '2025-05-28'
            ]
        }
        
        self.today = datetime(2025, 7, 4)
        self.df = None
        self.predictors = {}
        self.predictions = {}
        self.performance_summary = {}
        self.backtest_results = {}
        
    def _prepare_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        self.df = pd.DataFrame(self.data)
        self.df['date'] = pd.to_datetime(self.df['date'])
        self.df = self.df.sort_values('date').reset_index(drop=True)
        
        # åˆ›å»ºç‰¹å¾
        self.df['days_since_start'] = (self.df['date'] - self.df['date'].iloc[0]).dt.days
        self.df['month'] = self.df['date'].dt.month
        self.df['quarter'] = self.df['date'].dt.quarter
        self.df['year'] = self.df['date'].dt.year
        self.df['day_of_year'] = self.df['date'].dt.dayofyear
        self.df['interval_days'] = self.df['days_since_start'].diff()
        
        # ç‰ˆæœ¬ç‰¹å¾
        self.df['is_coder'] = self.df['version'].str.contains('Coder').astype(int)
        self.df['is_v2'] = self.df['version'].str.contains('V2').astype(int)
        self.df['is_v3'] = self.df['version'].str.contains('V3').astype(int)
        self.df['is_r1'] = self.df['version'].str.contains('R1').astype(int)
        
        print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
        print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {self.df.shape}")
        
    def _initialize_predictors(self):
        """åˆå§‹åŒ–æ‰€æœ‰é¢„æµ‹å™¨ï¼ˆæ’é™¤æ·±åº¦å­¦ä¹ ï¼‰"""
        print("ğŸ”§ åˆå§‹åŒ–é¢„æµ‹å™¨ï¼ˆæ’é™¤æ·±åº¦å­¦ä¹ ç®—æ³•ï¼‰...")
        
        # çº¿æ€§æ¨¡å‹ç»„
        self.predictors['Linear Models'] = {
            'Linear Regression': create_linear_predictor(),
            'Ridge Regression': create_ridge_predictor(), 
            'Lasso Regression': create_lasso_predictor()
        }
        
        # æ—¶é—´åºåˆ—ç»„
        self.predictors['Time Series'] = {
            'ARIMA': ARIMAPredictor(),
            'Exponential Smoothing': ExponentialSmoothingPredictor(),
            'Seasonal Pattern': SeasonalPredictor()
        }
        
        # é›†æˆå­¦ä¹ ç»„
        self.predictors['Ensemble Models'] = {
            'Random Forest': RandomForestPredictor(),
            'Gradient Boosting': GradientBoostingPredictor(),
            'XGBoost': XGBoostPredictor(),
            'SVR': SVRPredictor()
        }
        
        # é—´éš”åˆ†æç»„
        self.predictors['Interval Based'] = {
            'Mean Interval': create_mean_interval_predictor(),
            'Median Interval': create_median_interval_predictor(),
            'Recent 3 Mean': create_recent_interval_predictor(),
            'Adaptive Interval': create_adaptive_interval_predictor(),
            'Weighted Interval': create_weighted_interval_predictor()
        }
        
        # æ’é™¤ç¥ç»ç½‘ç»œç»„
        # self.predictors['Neural Networks'] = {
        #     'MLP': MLPPredictor(),
        #     'LSTM': LSTMPredictor()
        # }
        
        # ç»Ÿè®¡å­¦ç»„
        self.predictors['Statistical'] = {
            'Trend Analysis': TrendAnalysisPredictor(),
            'Seasonal Decompose': SeasonalDecomposePredictor(),
            'Statistical Ensemble': StatisticalPredictor()
        }
        
        # è®¡ç®—æ€»æ•°
        total_predictors = sum(len(group) for group in self.predictors.values())
        print(f"ğŸ¯ å·²åˆå§‹åŒ– {total_predictors} ä¸ªé¢„æµ‹å™¨ï¼Œåˆ†ä¸º {len(self.predictors)} ä¸ªç±»åˆ«")
        print("ğŸš« å·²æ’é™¤æ·±åº¦å­¦ä¹ ç®—æ³•ï¼šMLPå’ŒLSTM")
        
    def fit_all_models(self):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
        
        trained_count = 0
        failed_count = 0
        
        for group_name, group_predictors in self.predictors.items():
            print(f"\nğŸ“‹ è®­ç»ƒ {group_name} ç»„...")
            
            for name, predictor in group_predictors.items():
                try:
                    predictor.fit(self.df)
                    if predictor.is_fitted:
                        trained_count += 1
                        print(f"  âœ… {name}")
                    else:
                        failed_count += 1
                        print(f"  âŒ {name} - è®­ç»ƒå¤±è´¥")
                except Exception as e:
                    failed_count += 1
                    print(f"  âŒ {name} - é”™è¯¯: {e}")
        
        print(f"\nğŸ“ˆ è®­ç»ƒå®Œæˆ! æˆåŠŸ: {trained_count}, å¤±è´¥: {failed_count}")
    
    def generate_all_predictions(self, n_predictions=5):
        """ç”Ÿæˆæ‰€æœ‰é¢„æµ‹"""
        print(f"\nğŸ”® ç”Ÿæˆé¢„æµ‹ (æœªæ¥ {n_predictions} ä¸ªæ¨¡å‹)...")
        
        prediction_count = 0
        
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                if predictor.is_fitted:
                    try:
                        preds = predictor.predict(self.df, n_predictions, self.today)
                        # è¿‡æ»¤æœ‰æ•ˆé¢„æµ‹
                        valid_preds = [p for p in preds if p > self.today]
                        if valid_preds:
                            self.predictions[name] = valid_preds
                            prediction_count += 1
                    except Exception as e:
                        print(f"  âŒ {name} é¢„æµ‹å¤±è´¥: {e}")
        
        print(f"âœ… ç”Ÿæˆäº† {prediction_count} ä¸ªæœ‰æ•ˆé¢„æµ‹ç»“æœ")
        return self.predictions
    
    def analyze_performance(self):
        """åˆ†ææ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š åˆ†ææ¨¡å‹æ€§èƒ½...")
        
        performance_data = []
        
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                if predictor.is_fitted and predictor.performance_metrics:
                    metrics = predictor.performance_metrics.copy()
                    metrics['Name'] = name
                    metrics['Group'] = group_name
                    performance_data.append(metrics)
        
        if performance_data:
            perf_df = pd.DataFrame(performance_data)
            
            # æŒ‰RÂ²æ’åº
            if 'R2' in perf_df.columns:
                perf_df = perf_df.sort_values('R2', ascending=False)
                
                print("\nğŸ† Top 5 æ¨¡å‹æ€§èƒ½ (RÂ² Score):")
                print("-" * 50)
                for i, row in perf_df.head().iterrows():
                    print(f"{row['Name']}: {row['R2']:.4f}")
            
            self.performance_summary = perf_df
        else:
            print("âš ï¸  æ²¡æœ‰å¯ç”¨çš„æ€§èƒ½æ•°æ®")
    
    def create_comprehensive_analysis(self):
        """åˆ›å»ºç»¼åˆåˆ†æ"""
        print("\nğŸ“ˆ åˆ›å»ºç»¼åˆåˆ†æ...")
        
        # æ”¶é›†æ‰€æœ‰ç¬¬ä¸€ä¸ªé¢„æµ‹
        first_predictions = []
        for name, dates in self.predictions.items():
            if dates:
                first_predictions.append({
                    'Method': name,
                    'Date': dates[0],
                    'Days_from_now': (dates[0] - self.today).days
                })
        
        if not first_predictions:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹ç»“æœ")
            return
        
        pred_df = pd.DataFrame(first_predictions)
        pred_df = pred_df.sort_values('Days_from_now')
        
        # åˆ†æç»“æœ
        earliest = pred_df.iloc[0]
        latest = pred_df.iloc[-1]
        
        # 3ä¸ªæœˆå†…çš„é¢„æµ‹
        three_months_later = self.today + timedelta(days=90)
        near_term = pred_df[pred_df['Date'] <= three_months_later]
        
        print("\nğŸ¯ é¢„æµ‹åˆ†æç»“æœ:")
        print("=" * 60)
        print(f"ğŸ“… é¢„æµ‹åŸºå‡†æ—¥æœŸ: {self.today.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        print(f"ğŸ“Š æœ‰æ•ˆé¢„æµ‹æ–¹æ³•: {len(self.predictions)} ç§")
        print(f"âš¡ æœ€æ—©é¢„æµ‹: {earliest['Date'].strftime('%Yå¹´%mæœˆ%dæ—¥')} ({earliest['Method']})")
        print(f"â° è·ç¦»æœ€æ—©é¢„æµ‹: {earliest['Days_from_now']} å¤©")
        print(f"ğŸ”„ é¢„æµ‹æ—¶é—´è·¨åº¦: {(latest['Date'] - earliest['Date']).days} å¤©")
        print(f"ğŸ“ 3ä¸ªæœˆå†…é¢„æµ‹æ•°: {len(near_term)} ä¸ªæ–¹æ³•")
        
        # ä¸€è‡´æ€§è¯„çº§
        consistency_ratio = len(near_term) / len(pred_df)
        if consistency_ratio >= 0.6:
            consistency = "â­â­â­ é«˜ä¸€è‡´æ€§"
        elif consistency_ratio >= 0.4:
            consistency = "â­â­ ä¸­ç­‰ä¸€è‡´æ€§"
        else:
            consistency = "â­ ä½ä¸€è‡´æ€§"
        
        print(f"ğŸ–ï¸  é¢„æµ‹ä¸€è‡´æ€§: {consistency} ({consistency_ratio:.1%})")
        
        return {
            'earliest_prediction': earliest,
            'prediction_count': len(self.predictions),
            'near_term_count': len(near_term),
            'consistency': consistency
        }
    
    def create_advanced_visualizations(self):
        """åˆ›å»ºé«˜çº§å¯è§†åŒ–"""
        print("\nğŸ¨ åˆ›å»ºé«˜çº§å¯è§†åŒ–...")
        
        fig = make_subplots(
            rows=4, cols=2,
            subplot_titles=[
                'ğŸ“ˆ å†å²å‘å¸ƒæ—¶é—´çº¿', 'ğŸ“Š å‘å¸ƒé—´éš”åˆ†æ',
                'ğŸ”® é¢„æµ‹ç»“æœå¯¹æ¯” (æŒ‰æ–¹æ³•åˆ†ç»„)', 'âš¡ æœ€æ—©é¢„æµ‹åˆ†å¸ƒ',
                'ğŸ† æ¨¡å‹æ€§èƒ½æ’å', 'ğŸ“… é¢„æµ‹æ—¥æœŸçƒ­åŠ›å›¾',
                'ğŸ“Š é¢„æµ‹ä¸€è‡´æ€§åˆ†æ', 'ğŸ¯ ç»¼åˆé¢„æµ‹å»ºè®®'
            ],
            specs=[
                [{"secondary_y": False}, {"secondary_y": False}],
                [{"colspan": 2}, None],
                [{"secondary_y": False}, {"secondary_y": False}],
                [{"secondary_y": False}, {"secondary_y": False}]
            ]
        )
        
        # 1. å†å²æ—¶é—´çº¿
        fig.add_trace(
            go.Scatter(
                x=self.df['date'],
                y=list(range(len(self.df))),
                mode='markers+lines',
                name='å†å²å‘å¸ƒ',
                text=self.df['version'],
                hovertemplate='%{text}<br>%{x}<extra></extra>',
                marker=dict(size=12, color='gold', symbol='diamond'),
                line=dict(color='lightblue', width=3)
            ),
            row=1, col=1
        )
        
        # 2. å‘å¸ƒé—´éš”
        intervals = self.df['interval_days'].dropna()
        fig.add_trace(
            go.Bar(
                x=self.df['version'].iloc[1:],
                y=intervals,
                name='å‘å¸ƒé—´éš”(å¤©)',
                text=[f'{int(x)}å¤©' for x in intervals],
                textposition='auto',
                marker_color='lightcoral'
            ),
            row=1, col=2
        )
        
        # 3. é¢„æµ‹ç»“æœå¯¹æ¯” (æŒ‰ç»„åˆ†ç±»)
        colors = px.colors.qualitative.Set3
        method_groups = {}
        
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                if name in self.predictions:
                    method_groups[name] = group_name
        
        # ä¸ºæ¯ä¸ªç»„åˆ†é…é¢œè‰²
        unique_groups = list(set(method_groups.values()))
        group_colors = {group: colors[i % len(colors)] for i, group in enumerate(unique_groups)}
        
        for i, (method, dates) in enumerate(self.predictions.items()):
            if dates:
                group = method_groups.get(method, 'Other')
                fig.add_trace(
                    go.Scatter(
                        x=dates,
                        y=[f'{method}'] * len(dates),
                        mode='markers',
                        marker=dict(size=10, color=group_colors.get(group, 'gray')),
                        name=f'{group}: {method}',
                        text=[f'é¢„æµ‹ {j+1}' for j in range(len(dates))],
                        hovertemplate='%{text}<br>%{x}<extra></extra>',
                        showlegend=(i < 10)  # åªæ˜¾ç¤ºå‰10ä¸ªå›¾ä¾‹
                    ),
                    row=2, col=1
                )
        
        # æ·»åŠ ä»Šå¤©çš„æ ‡è®°çº¿ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        if self.predictions:
            today_line = go.Scatter(
                x=[self.today, self.today],
                y=[0, len(self.predictions)],
                mode='lines',
                line=dict(color='red', dash='dash', width=2),
                name='ä»Šå¤©',
                showlegend=True
            )
            fig.add_trace(today_line, row=2, col=1)
        
        # 4. æœ€æ—©é¢„æµ‹åˆ†å¸ƒ
        first_predictions = [dates[0] for dates in self.predictions.values() if dates]
        if first_predictions:
            pred_months = [d.strftime('%Y-%m') for d in first_predictions]
            month_counts = pd.Series(pred_months).value_counts().sort_index()
            
            fig.add_trace(
                go.Bar(
                    x=month_counts.index,
                    y=month_counts.values,
                    name='é¢„æµ‹é›†ä¸­åº¦',
                    marker_color='lightsteelblue',
                    text=month_counts.values,
                    textposition='auto'
                ),
                row=3, col=2
            )
        
        # 5. æ¨¡å‹æ€§èƒ½æ’å
        if hasattr(self, 'performance_summary') and not self.performance_summary.empty:
            top_performers = self.performance_summary.head(8)
            fig.add_trace(
                go.Bar(
                    x=top_performers['Name'],
                    y=top_performers['R2'],
                    name='RÂ² Score',
                    text=[f'{x:.3f}' for x in top_performers['R2']],
                    textposition='auto',
                    marker_color='lightgreen'
                ),
                row=4, col=1
            )
        
        # 6. é¢„æµ‹ç»Ÿè®¡
        if first_predictions:
            # æŒ‰å‘¨ç»Ÿè®¡
            week_data = {}
            for pred in first_predictions:
                week = pred.strftime('%Y-W%U')
                week_data[week] = week_data.get(week, 0) + 1
            
            if week_data:
                fig.add_trace(
                    go.Bar(
                        x=list(week_data.keys()),
                        y=list(week_data.values()),
                        name='æŒ‰å‘¨é¢„æµ‹åˆ†å¸ƒ',
                        marker_color='plum'
                    ),
                    row=4, col=2
                )
        
        fig.update_layout(
            height=1600,
            title_text="ğŸš€ DeepSeek æ¨¡å‹å‘å¸ƒé¢„æµ‹ - å…¨é¢åˆ†ææŠ¥å‘Š",
            showlegend=True
        )
        
        fig.write_html("deepseek_modular_analysis.html")
        print("âœ… é«˜çº§å¯è§†åŒ–å·²ä¿å­˜åˆ° deepseek_modular_analysis.html")
        
        return fig
    
    def print_detailed_results(self):
        """æ‰“å°è¯¦ç»†ç»“æœ"""
        print("\n" + "="*80)
        print("ğŸš€ DEEPSEEK æ¨¡å—åŒ–é¢„æµ‹ç»“æœ")
        print("="*80)
        
        # æŒ‰ç»„æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        for group_name, group_predictors in self.predictors.items():
            group_predictions = {}
            for name, predictor in group_predictors.items():
                if name in self.predictions:
                    group_predictions[name] = self.predictions[name]
            
            if group_predictions:
                print(f"\nğŸ“‹ {group_name} ç»„é¢„æµ‹:")
                print("-" * 50)
                
                for name, dates in group_predictions.items():
                    print(f"\nğŸ”¹ {name}:")
                    for i, date in enumerate(dates[:3], 1):
                        days_from_now = (date - self.today).days
                        print(f"   ç¬¬{i}ä¸ªæ¨¡å‹: {date.strftime('%Yå¹´%mæœˆ%dæ—¥')} (è·ä»Š {days_from_now} å¤©)")
        
        print("\n" + "="*80)
    
    def run_backtest(self, start_from=3, verbose=True):
        """
        è¿è¡Œå›æµ‹ï¼šä»ç¬¬start_fromä¸ªæ•°æ®ç‚¹å¼€å§‹ï¼Œé€æ­¥é¢„æµ‹ä¸‹ä¸€ä¸ªå‘å¸ƒæ—¶é—´
        
        Args:
            start_from: ä»ç¬¬å‡ ä¸ªæ•°æ®ç‚¹å¼€å§‹å›æµ‹ï¼ˆé»˜è®¤3ï¼Œå³ä»ç¬¬3æ¬¡å‘å¸ƒå¼€å§‹ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        print(f"\nğŸ”„ å¼€å§‹å›æµ‹åˆ†æ (ä»ç¬¬{start_from}ä¸ªæ•°æ®ç‚¹å¼€å§‹)")
        print("="*60)
        
        backtest_results = {}
        
        # è·å–æ‰€æœ‰é¢„æµ‹å™¨åç§°
        all_predictors = {}
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                all_predictors[name] = predictor
        
        # åˆå§‹åŒ–ç»“æœå­˜å‚¨
        for name in all_predictors.keys():
            backtest_results[name] = {
                'predictions': [],
                'actual_dates': [],
                'errors_days': [],
                'success_count': 0,
                'total_attempts': 0
            }
        
        # ä»ç¬¬start_fromä¸ªæ•°æ®ç‚¹å¼€å§‹é€æ­¥é¢„æµ‹
        for i in range(start_from, len(self.df)):
            target_date = self.df.iloc[i]['date']
            target_version = self.df.iloc[i]['version']
            
            if verbose:
                print(f"\nğŸ“… é¢„æµ‹ç¬¬{i+1}ä¸ªå‘å¸ƒ: {target_version} ({target_date.strftime('%Y-%m-%d')})")
                print("-" * 40)
            
            # ä½¿ç”¨å‰iä¸ªæ•°æ®ç‚¹è®­ç»ƒå’Œé¢„æµ‹
            train_df = self.df.iloc[:i].copy()
            
            # é‡æ–°è®¡ç®—è®­ç»ƒæ•°æ®çš„ç‰¹å¾
            train_df['days_since_start'] = (train_df['date'] - train_df['date'].iloc[0]).dt.days
            train_df['month'] = train_df['date'].dt.month
            train_df['quarter'] = train_df['date'].dt.quarter
            train_df['year'] = train_df['date'].dt.year
            train_df['day_of_year'] = train_df['date'].dt.dayofyear
            train_df['interval_days'] = train_df['days_since_start'].diff()
            
            # ç‰ˆæœ¬ç‰¹å¾
            train_df['is_coder'] = train_df['version'].str.contains('Coder').astype(int)
            train_df['is_v2'] = train_df['version'].str.contains('V2').astype(int)
            train_df['is_v3'] = train_df['version'].str.contains('V3').astype(int)
            train_df['is_r1'] = train_df['version'].str.contains('R1').astype(int)
            
            # å¯¹æ¯ä¸ªé¢„æµ‹å™¨è¿›è¡Œè®­ç»ƒå’Œé¢„æµ‹
            for name, predictor in all_predictors.items():
                try:
                    # é‡æ–°åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹ä»¥é¿å…çŠ¶æ€æ±¡æŸ“
                    if name == 'Linear Regression':
                        predictor = create_linear_predictor()
                    elif name == 'Ridge Regression':
                        predictor = create_ridge_predictor()
                    elif name == 'Lasso Regression':
                        predictor = create_lasso_predictor()
                    elif name == 'ARIMA':
                        predictor = ARIMAPredictor()
                    elif name == 'Exponential Smoothing':
                        predictor = ExponentialSmoothingPredictor()
                    elif name == 'Seasonal Pattern':
                        predictor = SeasonalPredictor()
                    elif name == 'Random Forest':
                        predictor = RandomForestPredictor()
                    elif name == 'Gradient Boosting':
                        predictor = GradientBoostingPredictor()
                    elif name == 'XGBoost':
                        predictor = XGBoostPredictor()
                    elif name == 'SVR':
                        predictor = SVRPredictor()
                    elif name == 'Mean Interval':
                        predictor = create_mean_interval_predictor()
                    elif name == 'Median Interval':
                        predictor = create_median_interval_predictor()
                    elif name == 'Recent 3 Mean':
                        predictor = create_recent_interval_predictor()
                    elif name == 'Adaptive Interval':
                        predictor = create_adaptive_interval_predictor()
                    elif name == 'Weighted Interval':
                        predictor = create_weighted_interval_predictor()
                    elif name == 'Trend Analysis':
                        predictor = TrendAnalysisPredictor()
                    elif name == 'Seasonal Decompose':
                        predictor = SeasonalDecomposePredictor()
                    elif name == 'Statistical Ensemble':
                        predictor = StatisticalPredictor()
                    
                    # è®­ç»ƒæ¨¡å‹
                    predictor.fit(train_df)
                    
                    if predictor.is_fitted:
                        # é¢„æµ‹ä¸‹ä¸€ä¸ªå‘å¸ƒæ—¶é—´
                        # ä½¿ç”¨è®­ç»ƒæ•°æ®çš„æœ€åä¸€å¤©ä½œä¸º"ä»Šå¤©"
                        last_known_date = train_df['date'].iloc[-1]
                        predictions = predictor.predict(train_df, n_predictions=1, today=last_known_date)
                        
                        backtest_results[name]['total_attempts'] += 1
                        
                        if predictions:
                            pred_date = predictions[0]
                            error_days = (pred_date - target_date).days
                            
                            backtest_results[name]['predictions'].append(pred_date)
                            backtest_results[name]['actual_dates'].append(target_date)
                            backtest_results[name]['errors_days'].append(error_days)
                            
                            if abs(error_days) <= 30:  # 30å¤©å†…ç®—æˆåŠŸ
                                backtest_results[name]['success_count'] += 1
                            
                            if verbose:
                                print(f"  ğŸ”¹ {name}: {pred_date.strftime('%Y-%m-%d')} (è¯¯å·®: {error_days:+d}å¤©)")
                        else:
                            backtest_results[name]['errors_days'].append(float('inf'))
                            if verbose:
                                print(f"  âŒ {name}: æ— é¢„æµ‹ç»“æœ")
                    else:
                        backtest_results[name]['total_attempts'] += 1
                        backtest_results[name]['errors_days'].append(float('inf'))
                        if verbose:
                            print(f"  âŒ {name}: è®­ç»ƒå¤±è´¥")
                            
                except Exception as e:
                    backtest_results[name]['total_attempts'] += 1
                    backtest_results[name]['errors_days'].append(float('inf'))
                    if verbose:
                        print(f"  âŒ {name}: é”™è¯¯ - {str(e)[:50]}...")
        
        # è®¡ç®—å›æµ‹ç»Ÿè®¡
        print(f"\nğŸ“Š å›æµ‹ç»Ÿè®¡åˆ†æ (å…±{len(self.df) - start_from}æ¬¡é¢„æµ‹)")
        print("="*60)
        
        backtest_summary = []
        for name, results in backtest_results.items():
            if results['total_attempts'] > 0:
                valid_errors = [e for e in results['errors_days'] if e != float('inf')]
                
                if valid_errors:
                    mae = np.mean(np.abs(valid_errors))
                    rmse = np.sqrt(np.mean(np.square(valid_errors)))
                    success_rate = results['success_count'] / results['total_attempts']
                    
                    backtest_summary.append({
                        'Method': name,
                        'MAE (days)': mae,
                        'RMSE (days)': rmse,
                        'Success_Rate': success_rate,
                        'Valid_Predictions': len(valid_errors),
                        'Total_Attempts': results['total_attempts']
                    })
        
        # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
        if backtest_summary:
            bt_df = pd.DataFrame(backtest_summary)
            bt_df = bt_df.sort_values('MAE (days)')
            
            print("\nğŸ† å›æµ‹æ’å (æŒ‰MAEæ’åº):")
            print("-" * 80)
            print(f"{'æ–¹æ³•':<20} {'MAE':<10} {'RMSE':<10} {'æˆåŠŸç‡':<10} {'æœ‰æ•ˆé¢„æµ‹':<10}")
            print("-" * 80)
            
            for _, row in bt_df.head(10).iterrows():
                print(f"{row['Method']:<20} {row['MAE (days)']:<10.1f} {row['RMSE (days)']:<10.1f} "
                      f"{row['Success_Rate']:<10.1%} {row['Valid_Predictions']:<10d}")
            
            self.backtest_results = backtest_results
            return bt_df
        else:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›æµ‹ç»“æœ")
            return None
    
    def compare_r2_vs_backtest(self):
        """æ¯”è¾ƒRÂ²å’Œå›æµ‹ç»“æœçš„å…³ç³»"""
        print("\nğŸ” æ¯”è¾ƒRÂ²å’Œå›æµ‹è¡¨ç°çš„å…³ç³»")
        print("="*60)
        
        if not hasattr(self, 'backtest_results') or not self.backtest_results:
            print("âŒ éœ€è¦å…ˆè¿è¡Œå›æµ‹åˆ†æ")
            return None
        
        # æ”¶é›†RÂ²å’Œå›æµ‹æ•°æ®
        comparison_data = []
        
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                # è·å–RÂ²åˆ†æ•°
                r2_score = None
                if hasattr(predictor, 'performance_metrics') and predictor.performance_metrics:
                    r2_score = predictor.performance_metrics.get('R2', None)
                
                # è·å–å›æµ‹ç»“æœ
                if name in self.backtest_results:
                    results = self.backtest_results[name]
                    valid_errors = [e for e in results['errors_days'] if e != float('inf')]
                    
                    if valid_errors and r2_score is not None:
                        mae = np.mean(np.abs(valid_errors))
                        rmse = np.sqrt(np.mean(np.square(valid_errors)))
                        success_rate = results['success_count'] / results['total_attempts']
                        
                        comparison_data.append({
                            'Method': name,
                            'Group': group_name,
                            'R2_Score': r2_score,
                            'MAE': mae,
                            'RMSE': rmse,
                            'Success_Rate': success_rate,
                            'Valid_Predictions': len(valid_errors)
                        })
        
        if not comparison_data:
            print("âŒ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œæ¯”è¾ƒ")
            return None
        
        comp_df = pd.DataFrame(comparison_data)
        
        # è®¡ç®—ç›¸å…³æ€§
        r2_mae_corr = comp_df['R2_Score'].corr(comp_df['MAE'])
        r2_success_corr = comp_df['R2_Score'].corr(comp_df['Success_Rate'])
        
        print(f"\nğŸ“Š ç›¸å…³æ€§åˆ†æ:")
        print(f"RÂ² vs MAEç›¸å…³æ€§: {r2_mae_corr:.3f}")
        print(f"RÂ² vs æˆåŠŸç‡ç›¸å…³æ€§: {r2_success_corr:.3f}")
        
        # æŒ‰ä¸åŒæŒ‡æ ‡æ’åº
        print(f"\nğŸ† æŒ‰RÂ²æ’åº vs æŒ‰MAEæ’åº:")
        print("-" * 60)
        print("RÂ²æ’åº (å‰5):")
        r2_top = comp_df.nlargest(5, 'R2_Score')
        for _, row in r2_top.iterrows():
            print(f"  {row['Method']:<20} RÂ²:{row['R2_Score']:.3f} MAE:{row['MAE']:.1f}")
        
        print("\nMAEæ’åº (å‰5):")
        mae_top = comp_df.nsmallest(5, 'MAE')
        for _, row in mae_top.iterrows():
            print(f"  {row['Method']:<20} RÂ²:{row['R2_Score']:.3f} MAE:{row['MAE']:.1f}")
        
        # æ‰¾å‡ºRÂ²é«˜ä½†MAEå¤§çš„æ–¹æ³•
        print(f"\nâš ï¸  RÂ²é«˜ä½†å›æµ‹è¡¨ç°å·®çš„æ–¹æ³•:")
        print("-" * 40)
        high_r2_poor_mae = comp_df[(comp_df['R2_Score'] > 0.8) & (comp_df['MAE'] > 100)]
        if not high_r2_poor_mae.empty:
            for _, row in high_r2_poor_mae.iterrows():
                print(f"  {row['Method']:<20} RÂ²:{row['R2_Score']:.3f} MAE:{row['MAE']:.1f}")
        else:
            print("  æ²¡æœ‰å‘ç°è¿™ç±»æ–¹æ³•")
        
        # æ‰¾å‡ºRÂ²ä½ä½†MAEå°çš„æ–¹æ³•
        print(f"\nâœ… RÂ²ä½ä½†å›æµ‹è¡¨ç°å¥½çš„æ–¹æ³•:")
        print("-" * 40)
        low_r2_good_mae = comp_df[(comp_df['R2_Score'] < 0.5) & (comp_df['MAE'] < 50)]
        if not low_r2_good_mae.empty:
            for _, row in low_r2_good_mae.iterrows():
                print(f"  {row['Method']:<20} RÂ²:{row['R2_Score']:.3f} MAE:{row['MAE']:.1f}")
        else:
            print("  æ²¡æœ‰å‘ç°è¿™ç±»æ–¹æ³•")
        
        print(f"\nğŸ“ ç»“è®º:")
        if abs(r2_mae_corr) < 0.3:
            print("âŒ RÂ²å’Œå›æµ‹è¡¨ç°ç›¸å…³æ€§å¾ˆå¼±ï¼ŒRÂ²ä¸æ˜¯é€‰æ‹©æ¨¡å‹çš„å¥½æŒ‡æ ‡")
        elif r2_mae_corr < -0.5:
            print("âœ… RÂ²å’Œå›æµ‹è¡¨ç°è´Ÿç›¸å…³è¾ƒå¼ºï¼ŒRÂ²æ˜¯é€‰æ‹©æ¨¡å‹çš„å¥½æŒ‡æ ‡")
        else:
            print("âš ï¸  RÂ²å’Œå›æµ‹è¡¨ç°ç›¸å…³æ€§ä¸­ç­‰ï¼Œå»ºè®®åŒæ—¶å‚è€ƒä¸¤ä¸ªæŒ‡æ ‡")
        
        return comp_df
    
    def create_backtest_visualization(self):
        """åˆ›å»ºå›æµ‹ç»“æœå¯è§†åŒ–"""
        print("\nğŸ¨ åˆ›å»ºå›æµ‹ç»“æœå¯è§†åŒ–...")
        
        if not hasattr(self, 'backtest_results') or not self.backtest_results:
            print("âŒ éœ€è¦å…ˆè¿è¡Œå›æµ‹åˆ†æ")
            return None
        
        # æ”¶é›†å›æµ‹æ•°æ®
        backtest_data = []
        for name, results in self.backtest_results.items():
            for i, (pred_date, actual_date, error) in enumerate(zip(
                results['predictions'], results['actual_dates'], results['errors_days']
            )):
                if error != float('inf'):
                    backtest_data.append({
                        'Method': name,
                        'Prediction_Number': i + 1,
                        'Predicted_Date': pred_date,
                        'Actual_Date': actual_date,
                        'Error_Days': error,
                        'Absolute_Error': abs(error)
                    })
        
        if not backtest_data:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›æµ‹æ•°æ®")
            return None
        
        bt_df = pd.DataFrame(backtest_data)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                'ğŸ“Š å„æ–¹æ³•å›æµ‹è¯¯å·®åˆ†å¸ƒ', 'ğŸ“ˆ å›æµ‹è¯¯å·®æ—¶é—´åºåˆ—',
                'ğŸ¯ é¢„æµ‹vså®é™…å¯¹æ¯”', 'ğŸ† æ–¹æ³•æ€§èƒ½é›·è¾¾å›¾'
            ],
            specs=[
                [{"type": "xy"}, {"type": "xy"}],
                [{"type": "xy"}, {"type": "polar"}]
            ]
        )
        
        # 1. è¯¯å·®åˆ†å¸ƒç®±çº¿å›¾
        methods = bt_df['Method'].unique()[:10]  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªæ–¹æ³•
        colors = px.colors.qualitative.Set3
        
        for i, method in enumerate(methods):
            method_data = bt_df[bt_df['Method'] == method]
            fig.add_trace(
                go.Box(
                    y=method_data['Error_Days'],
                    name=method,
                    marker_color=colors[i % len(colors)],
                    showlegend=False
                ),
                row=1, col=1
            )
        
        # 2. æ—¶é—´åºåˆ—è¯¯å·®
        for i, method in enumerate(methods[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªæ–¹æ³•
            method_data = bt_df[bt_df['Method'] == method].sort_values('Actual_Date')
            fig.add_trace(
                go.Scatter(
                    x=method_data['Actual_Date'],
                    y=method_data['Error_Days'],
                    mode='lines+markers',
                    name=method,
                    line=dict(color=colors[i % len(colors)]),
                    showlegend=True
                ),
                row=1, col=2
            )
        
        # 3. é¢„æµ‹vså®é™…æ•£ç‚¹å›¾
        for i, method in enumerate(methods[:5]):
            method_data = bt_df[bt_df['Method'] == method]
            fig.add_trace(
                go.Scatter(
                    x=method_data['Actual_Date'],
                    y=method_data['Predicted_Date'],
                    mode='markers',
                    name=method,
                    marker=dict(color=colors[i % len(colors)], size=8),
                    showlegend=False
                ),
                row=2, col=1
            )
        
        # æ·»åŠ ç†æƒ³çº¿ (y=x)
        min_date = bt_df['Actual_Date'].min()
        max_date = bt_df['Actual_Date'].max()
        fig.add_trace(
            go.Scatter(
                x=[min_date, max_date],
                y=[min_date, max_date],
                mode='lines',
                name='ç†æƒ³é¢„æµ‹',
                line=dict(color='red', dash='dash'),
                showlegend=False
            ),
            row=2, col=1
        )
        
        # 4. é›·è¾¾å›¾ - æ–¹æ³•æ€§èƒ½
        # è®¡ç®—æ¯ä¸ªæ–¹æ³•çš„ç»¼åˆæ€§èƒ½æŒ‡æ ‡
        method_stats = bt_df.groupby('Method').agg({
            'Absolute_Error': ['mean', 'std'],
            'Error_Days': lambda x: (abs(x) <= 30).mean()  # 30å¤©å†…å‡†ç¡®ç‡
        }).reset_index()
        
        method_stats.columns = ['Method', 'MAE', 'Std', 'Accuracy']
        method_stats = method_stats.head(6)  # å‰6ä¸ªæ–¹æ³•
        
        # æ ‡å‡†åŒ–æŒ‡æ ‡ (è¶Šå°è¶Šå¥½çš„è½¬æ¢ä¸ºè¶Šå¤§è¶Šå¥½)
        method_stats['MAE_Score'] = 1 / (1 + method_stats['MAE'] / 100)
        method_stats['Stability_Score'] = 1 / (1 + method_stats['Std'] / 100)
        
        # ä¸ºæ¯ä¸ªæ–¹æ³•åˆ›å»ºé›·è¾¾å›¾
        for i, row in method_stats.iterrows():
            fig.add_trace(
                go.Scatterpolar(
                    r=[row['MAE_Score'], row['Stability_Score'], row['Accuracy']],
                    theta=['å‡†ç¡®æ€§', 'ç¨³å®šæ€§', 'å‘½ä¸­ç‡'],
                    fill='toself',
                    name=row['Method'],
                    line=dict(color=colors[i % len(colors)]),
                    showlegend=False
                ),
                row=2, col=2
            )
        
        fig.update_layout(
            height=1000,
            title_text="ğŸ”„ DeepSeek å›æµ‹åˆ†ææŠ¥å‘Š",
            showlegend=True
        )
        
        fig.write_html("deepseek_backtest_analysis.html")
        print("âœ… å›æµ‹å¯è§†åŒ–å·²ä¿å­˜åˆ° deepseek_backtest_analysis.html")
        
        return fig
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸ¯ å¼€å§‹DeepSeekæ¨¡å‹å‘å¸ƒé¢„æµ‹å®Œæ•´åˆ†æ")
        print("="*60)
        
        # 1. æ•°æ®å‡†å¤‡
        self._prepare_data()
        
        # 2. åˆå§‹åŒ–é¢„æµ‹å™¨
        self._initialize_predictors()
        
        # 3. è®­ç»ƒæ¨¡å‹
        self.fit_all_models()
        
        # 4. ç”Ÿæˆé¢„æµ‹
        self.generate_all_predictions()
        
        # 5. æ€§èƒ½åˆ†æ
        self.analyze_performance()
        
        # 6. ç»¼åˆåˆ†æ
        analysis_summary = self.create_comprehensive_analysis()
        
        # 7. æ‰“å°è¯¦ç»†ç»“æœ
        self.print_detailed_results()
        
        # 8. åˆ›å»ºå¯è§†åŒ–
        self.create_advanced_visualizations()
        
        # 9. è¿è¡Œå›æµ‹
        self.run_backtest()
        
        # 10. æ¯”è¾ƒRÂ²å’Œå›æµ‹ç»“æœçš„å…³ç³»
        self.compare_r2_vs_backtest()
        
        # 11. åˆ›å»ºå›æµ‹å¯è§†åŒ–
        self.create_backtest_visualization()
        
        print("\nğŸ‰ åˆ†æå®Œæˆ!")
        return {
            'predictions': self.predictions,
            'performance': self.performance_summary,
            'summary': analysis_summary,
            'backtest_results': self.backtest_results
        }


def main():
    """ä¸»å‡½æ•°"""
    predictor = DeepSeekPredictorModular()
    results = predictor.run_complete_analysis()
    return predictor, results


if __name__ == "__main__":
    predictor, results = main() 