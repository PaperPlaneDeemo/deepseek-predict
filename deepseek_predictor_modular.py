"""
DeepSeekæ¨¡å‹å‘å¸ƒé¢„æµ‹å™¨ - æ¨¡å—åŒ–ç‰ˆæœ¬
æ•´åˆæ‰€æœ‰ç‹¬ç«‹çš„é¢„æµ‹æ–¹æ³•ï¼Œæä¾›ç»Ÿä¸€çš„é¢„æµ‹æ¥å£
"""

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from typing import Dict, List

# å¯¼å…¥æ‰€æœ‰é¢„æµ‹å™¨
from models.linear_models import create_linear_predictor, create_ridge_predictor, create_lasso_predictor
from models.time_series import ARIMAPredictor, ExponentialSmoothingPredictor, SeasonalPredictor
from models.ensemble_models import RandomForestPredictor, GradientBoostingPredictor, XGBoostPredictor, SVRPredictor
from models.interval_based import (
    create_mean_interval_predictor, create_median_interval_predictor,
    create_recent_interval_predictor, create_adaptive_interval_predictor,
    create_weighted_interval_predictor
)
from models.neural_networks import MLPPredictor, LSTMPredictor
from models.statistical import TrendAnalysisPredictor, SeasonalDecomposePredictor, StatisticalPredictor


class DeepSeekPredictorModular:
    """æ¨¡å—åŒ–DeepSeeké¢„æµ‹å™¨"""
    
    def __init__(self):
        # åŸå§‹æ•°æ®
        self.data = {
            'version': [
                'DeepSeek Coder', 'DeepSeek-LLM', 'DeepSeek-V2 (Apr)',
                'DeepSeek-Coder V2 (Jun)', 'DeepSeek-V2 (Jun)', 'DeepSeek-Coder V2 (Jul)',
                'DeepSeek-V2.5 (Sep)', 'DeepSeek-V3', 'DeepSeek-V2.5 (Dec)',
                'DeepSeek-R1', 'DeepSeek-V3-0324', 'DeepSeek-R1-0528'
            ],
            'date': [
                '2023-11-02', '2023-11-29', '2024-04-28', '2024-06-14',
                '2024-06-28', '2024-07-24', '2024-09-05', '2024-12-25',
                '2024-12-10', '2025-01-20', '2025-03-24', '2025-05-28'
            ]
        }
        
        self.today = datetime(2025, 7, 4)
        self.df = None
        self.predictors = {}
        self.predictions = {}
        self.performance_summary = {}
        
    def _prepare_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        self.df = pd.DataFrame(self.data)
        self.df['date'] = pd.to_datetime(self.df['date'])
        self.df = self.df.sort_values('date').reset_index(drop=True)
        
        # åˆ›å»ºç‰¹å¾
        self.df['days_since_start'] = (self.df['date'] - self.df['date'].iloc[0]).dt.days
        self.df['month'] = self.df['date'].dt.month
        self.df['quarter'] = self.df['date'].dt.quarter
        self.df['year'] = self.df['date'].dt.year
        self.df['day_of_year'] = self.df['date'].dt.dayofyear
        self.df['interval_days'] = self.df['days_since_start'].diff()
        
        # ç‰ˆæœ¬ç‰¹å¾
        self.df['is_coder'] = self.df['version'].str.contains('Coder').astype(int)
        self.df['is_v2'] = self.df['version'].str.contains('V2').astype(int)
        self.df['is_v3'] = self.df['version'].str.contains('V3').astype(int)
        self.df['is_r1'] = self.df['version'].str.contains('R1').astype(int)
        
        print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
        print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {self.df.shape}")
        
    def _initialize_predictors(self):
        """åˆå§‹åŒ–æ‰€æœ‰é¢„æµ‹å™¨"""
        print("ğŸ”§ åˆå§‹åŒ–é¢„æµ‹å™¨...")
        
        # çº¿æ€§æ¨¡å‹ç»„
        self.predictors['Linear Models'] = {
            'Linear Regression': create_linear_predictor(),
            'Ridge Regression': create_ridge_predictor(), 
            'Lasso Regression': create_lasso_predictor()
        }
        
        # æ—¶é—´åºåˆ—ç»„
        self.predictors['Time Series'] = {
            'ARIMA': ARIMAPredictor(),
            'Exponential Smoothing': ExponentialSmoothingPredictor(),
            'Seasonal Pattern': SeasonalPredictor()
        }
        
        # é›†æˆå­¦ä¹ ç»„
        self.predictors['Ensemble Models'] = {
            'Random Forest': RandomForestPredictor(),
            'Gradient Boosting': GradientBoostingPredictor(),
            'XGBoost': XGBoostPredictor(),
            'SVR': SVRPredictor()
        }
        
        # é—´éš”åˆ†æç»„
        self.predictors['Interval Based'] = {
            'Mean Interval': create_mean_interval_predictor(),
            'Median Interval': create_median_interval_predictor(),
            'Recent 3 Mean': create_recent_interval_predictor(),
            'Adaptive Interval': create_adaptive_interval_predictor(),
            'Weighted Interval': create_weighted_interval_predictor()
        }
        
        # ç¥ç»ç½‘ç»œç»„
        self.predictors['Neural Networks'] = {
            'MLP': MLPPredictor(),
            'LSTM': LSTMPredictor()
        }
        
        # ç»Ÿè®¡å­¦ç»„
        self.predictors['Statistical'] = {
            'Trend Analysis': TrendAnalysisPredictor(),
            'Seasonal Decompose': SeasonalDecomposePredictor(),
            'Statistical Ensemble': StatisticalPredictor()
        }
        
        # è®¡ç®—æ€»æ•°
        total_predictors = sum(len(group) for group in self.predictors.values())
        print(f"ğŸ¯ å·²åˆå§‹åŒ– {total_predictors} ä¸ªé¢„æµ‹å™¨ï¼Œåˆ†ä¸º {len(self.predictors)} ä¸ªç±»åˆ«")
        
    def fit_all_models(self):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
        
        trained_count = 0
        failed_count = 0
        
        for group_name, group_predictors in self.predictors.items():
            print(f"\nğŸ“‹ è®­ç»ƒ {group_name} ç»„...")
            
            for name, predictor in group_predictors.items():
                try:
                    predictor.fit(self.df)
                    if predictor.is_fitted:
                        trained_count += 1
                        print(f"  âœ… {name}")
                    else:
                        failed_count += 1
                        print(f"  âŒ {name} - è®­ç»ƒå¤±è´¥")
                except Exception as e:
                    failed_count += 1
                    print(f"  âŒ {name} - é”™è¯¯: {e}")
        
        print(f"\nğŸ“ˆ è®­ç»ƒå®Œæˆ! æˆåŠŸ: {trained_count}, å¤±è´¥: {failed_count}")
    
    def generate_all_predictions(self, n_predictions=5):
        """ç”Ÿæˆæ‰€æœ‰é¢„æµ‹"""
        print(f"\nğŸ”® ç”Ÿæˆé¢„æµ‹ (æœªæ¥ {n_predictions} ä¸ªæ¨¡å‹)...")
        
        prediction_count = 0
        
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                if predictor.is_fitted:
                    try:
                        preds = predictor.predict(self.df, n_predictions, self.today)
                        # è¿‡æ»¤æœ‰æ•ˆé¢„æµ‹
                        valid_preds = [p for p in preds if p > self.today]
                        if valid_preds:
                            self.predictions[name] = valid_preds
                            prediction_count += 1
                    except Exception as e:
                        print(f"  âŒ {name} é¢„æµ‹å¤±è´¥: {e}")
        
        print(f"âœ… ç”Ÿæˆäº† {prediction_count} ä¸ªæœ‰æ•ˆé¢„æµ‹ç»“æœ")
        return self.predictions
    
    def analyze_performance(self):
        """åˆ†ææ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š åˆ†ææ¨¡å‹æ€§èƒ½...")
        
        performance_data = []
        
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                if predictor.is_fitted and predictor.performance_metrics:
                    metrics = predictor.performance_metrics.copy()
                    metrics['Name'] = name
                    metrics['Group'] = group_name
                    performance_data.append(metrics)
        
        if performance_data:
            perf_df = pd.DataFrame(performance_data)
            
            # æŒ‰RÂ²æ’åº
            if 'R2' in perf_df.columns:
                perf_df = perf_df.sort_values('R2', ascending=False)
                
                print("\nğŸ† Top 5 æ¨¡å‹æ€§èƒ½ (RÂ² Score):")
                print("-" * 50)
                for i, row in perf_df.head().iterrows():
                    print(f"{row['Name']}: {row['R2']:.4f}")
            
            self.performance_summary = perf_df
        else:
            print("âš ï¸  æ²¡æœ‰å¯ç”¨çš„æ€§èƒ½æ•°æ®")
    
    def create_comprehensive_analysis(self):
        """åˆ›å»ºç»¼åˆåˆ†æ"""
        print("\nğŸ“ˆ åˆ›å»ºç»¼åˆåˆ†æ...")
        
        # æ”¶é›†æ‰€æœ‰ç¬¬ä¸€ä¸ªé¢„æµ‹
        first_predictions = []
        for name, dates in self.predictions.items():
            if dates:
                first_predictions.append({
                    'Method': name,
                    'Date': dates[0],
                    'Days_from_now': (dates[0] - self.today).days
                })
        
        if not first_predictions:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„é¢„æµ‹ç»“æœ")
            return
        
        pred_df = pd.DataFrame(first_predictions)
        pred_df = pred_df.sort_values('Days_from_now')
        
        # åˆ†æç»“æœ
        earliest = pred_df.iloc[0]
        latest = pred_df.iloc[-1]
        
        # 3ä¸ªæœˆå†…çš„é¢„æµ‹
        three_months_later = self.today + timedelta(days=90)
        near_term = pred_df[pred_df['Date'] <= three_months_later]
        
        print("\nğŸ¯ é¢„æµ‹åˆ†æç»“æœ:")
        print("=" * 60)
        print(f"ğŸ“… é¢„æµ‹åŸºå‡†æ—¥æœŸ: {self.today.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        print(f"ğŸ“Š æœ‰æ•ˆé¢„æµ‹æ–¹æ³•: {len(self.predictions)} ç§")
        print(f"âš¡ æœ€æ—©é¢„æµ‹: {earliest['Date'].strftime('%Yå¹´%mæœˆ%dæ—¥')} ({earliest['Method']})")
        print(f"â° è·ç¦»æœ€æ—©é¢„æµ‹: {earliest['Days_from_now']} å¤©")
        print(f"ğŸ”„ é¢„æµ‹æ—¶é—´è·¨åº¦: {(latest['Date'] - earliest['Date']).days} å¤©")
        print(f"ğŸ“ 3ä¸ªæœˆå†…é¢„æµ‹æ•°: {len(near_term)} ä¸ªæ–¹æ³•")
        
        # ä¸€è‡´æ€§è¯„çº§
        consistency_ratio = len(near_term) / len(pred_df)
        if consistency_ratio >= 0.6:
            consistency = "â­â­â­ é«˜ä¸€è‡´æ€§"
        elif consistency_ratio >= 0.4:
            consistency = "â­â­ ä¸­ç­‰ä¸€è‡´æ€§"
        else:
            consistency = "â­ ä½ä¸€è‡´æ€§"
        
        print(f"ğŸ–ï¸  é¢„æµ‹ä¸€è‡´æ€§: {consistency} ({consistency_ratio:.1%})")
        
        return {
            'earliest_prediction': earliest,
            'prediction_count': len(self.predictions),
            'near_term_count': len(near_term),
            'consistency': consistency
        }
    
    def create_advanced_visualizations(self):
        """åˆ›å»ºé«˜çº§å¯è§†åŒ–"""
        print("\nğŸ¨ åˆ›å»ºé«˜çº§å¯è§†åŒ–...")
        
        fig = make_subplots(
            rows=4, cols=2,
            subplot_titles=[
                'ğŸ“ˆ å†å²å‘å¸ƒæ—¶é—´çº¿', 'ğŸ“Š å‘å¸ƒé—´éš”åˆ†æ',
                'ğŸ”® é¢„æµ‹ç»“æœå¯¹æ¯” (æŒ‰æ–¹æ³•åˆ†ç»„)', 'âš¡ æœ€æ—©é¢„æµ‹åˆ†å¸ƒ',
                'ğŸ† æ¨¡å‹æ€§èƒ½æ’å', 'ğŸ“… é¢„æµ‹æ—¥æœŸçƒ­åŠ›å›¾',
                'ğŸ“Š é¢„æµ‹ä¸€è‡´æ€§åˆ†æ', 'ğŸ¯ ç»¼åˆé¢„æµ‹å»ºè®®'
            ],
            specs=[
                [{"secondary_y": False}, {"secondary_y": False}],
                [{"colspan": 2}, None],
                [{"secondary_y": False}, {"secondary_y": False}],
                [{"secondary_y": False}, {"secondary_y": False}]
            ]
        )
        
        # 1. å†å²æ—¶é—´çº¿
        fig.add_trace(
            go.Scatter(
                x=self.df['date'],
                y=list(range(len(self.df))),
                mode='markers+lines',
                name='å†å²å‘å¸ƒ',
                text=self.df['version'],
                hovertemplate='%{text}<br>%{x}<extra></extra>',
                marker=dict(size=12, color='gold', symbol='diamond'),
                line=dict(color='lightblue', width=3)
            ),
            row=1, col=1
        )
        
        # 2. å‘å¸ƒé—´éš”
        intervals = self.df['interval_days'].dropna()
        fig.add_trace(
            go.Bar(
                x=self.df['version'].iloc[1:],
                y=intervals,
                name='å‘å¸ƒé—´éš”(å¤©)',
                text=[f'{int(x)}å¤©' for x in intervals],
                textposition='auto',
                marker_color='lightcoral'
            ),
            row=1, col=2
        )
        
        # 3. é¢„æµ‹ç»“æœå¯¹æ¯” (æŒ‰ç»„åˆ†ç±»)
        colors = px.colors.qualitative.Set3
        method_groups = {}
        
        for group_name, group_predictors in self.predictors.items():
            for name, predictor in group_predictors.items():
                if name in self.predictions:
                    method_groups[name] = group_name
        
        # ä¸ºæ¯ä¸ªç»„åˆ†é…é¢œè‰²
        unique_groups = list(set(method_groups.values()))
        group_colors = {group: colors[i % len(colors)] for i, group in enumerate(unique_groups)}
        
        for i, (method, dates) in enumerate(self.predictions.items()):
            if dates:
                group = method_groups.get(method, 'Other')
                fig.add_trace(
                    go.Scatter(
                        x=dates,
                        y=[f'{method}'] * len(dates),
                        mode='markers',
                        marker=dict(size=10, color=group_colors.get(group, 'gray')),
                        name=f'{group}: {method}',
                        text=[f'é¢„æµ‹ {j+1}' for j in range(len(dates))],
                        hovertemplate='%{text}<br>%{x}<extra></extra>',
                        showlegend=(i < 10)  # åªæ˜¾ç¤ºå‰10ä¸ªå›¾ä¾‹
                    ),
                    row=2, col=1
                )
        
        # æ·»åŠ ä»Šå¤©çš„æ ‡è®°çº¿ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        if self.predictions:
            today_line = go.Scatter(
                x=[self.today, self.today],
                y=[0, len(self.predictions)],
                mode='lines',
                line=dict(color='red', dash='dash', width=2),
                name='ä»Šå¤©',
                showlegend=True
            )
            fig.add_trace(today_line, row=2, col=1)
        
        # 4. æœ€æ—©é¢„æµ‹åˆ†å¸ƒ
        first_predictions = [dates[0] for dates in self.predictions.values() if dates]
        if first_predictions:
            pred_months = [d.strftime('%Y-%m') for d in first_predictions]
            month_counts = pd.Series(pred_months).value_counts().sort_index()
            
            fig.add_trace(
                go.Bar(
                    x=month_counts.index,
                    y=month_counts.values,
                    name='é¢„æµ‹é›†ä¸­åº¦',
                    marker_color='lightsteelblue',
                    text=month_counts.values,
                    textposition='auto'
                ),
                row=3, col=2
            )
        
        # 5. æ¨¡å‹æ€§èƒ½æ’å
        if hasattr(self, 'performance_summary') and not self.performance_summary.empty:
            top_performers = self.performance_summary.head(8)
            fig.add_trace(
                go.Bar(
                    x=top_performers['Name'],
                    y=top_performers['R2'],
                    name='RÂ² Score',
                    text=[f'{x:.3f}' for x in top_performers['R2']],
                    textposition='auto',
                    marker_color='lightgreen'
                ),
                row=4, col=1
            )
        
        # 6. é¢„æµ‹ç»Ÿè®¡
        if first_predictions:
            # æŒ‰å‘¨ç»Ÿè®¡
            week_data = {}
            for pred in first_predictions:
                week = pred.strftime('%Y-W%U')
                week_data[week] = week_data.get(week, 0) + 1
            
            if week_data:
                fig.add_trace(
                    go.Bar(
                        x=list(week_data.keys()),
                        y=list(week_data.values()),
                        name='æŒ‰å‘¨é¢„æµ‹åˆ†å¸ƒ',
                        marker_color='plum'
                    ),
                    row=4, col=2
                )
        
        fig.update_layout(
            height=1600,
            title_text="ğŸš€ DeepSeek æ¨¡å‹å‘å¸ƒé¢„æµ‹ - å…¨é¢åˆ†ææŠ¥å‘Š",
            showlegend=True
        )
        
        fig.write_html("deepseek_modular_analysis.html")
        print("âœ… é«˜çº§å¯è§†åŒ–å·²ä¿å­˜åˆ° deepseek_modular_analysis.html")
        
        return fig
    
    def print_detailed_results(self):
        """æ‰“å°è¯¦ç»†ç»“æœ"""
        print("\n" + "="*80)
        print("ğŸš€ DEEPSEEK æ¨¡å—åŒ–é¢„æµ‹ç»“æœ")
        print("="*80)
        
        # æŒ‰ç»„æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        for group_name, group_predictors in self.predictors.items():
            group_predictions = {}
            for name, predictor in group_predictors.items():
                if name in self.predictions:
                    group_predictions[name] = self.predictions[name]
            
            if group_predictions:
                print(f"\nğŸ“‹ {group_name} ç»„é¢„æµ‹:")
                print("-" * 50)
                
                for name, dates in group_predictions.items():
                    print(f"\nğŸ”¹ {name}:")
                    for i, date in enumerate(dates[:3], 1):
                        days_from_now = (date - self.today).days
                        print(f"   ç¬¬{i}ä¸ªæ¨¡å‹: {date.strftime('%Yå¹´%mæœˆ%dæ—¥')} (è·ä»Š {days_from_now} å¤©)")
        
        print("\n" + "="*80)
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸ¯ å¼€å§‹DeepSeekæ¨¡å‹å‘å¸ƒé¢„æµ‹å®Œæ•´åˆ†æ")
        print("="*60)
        
        # 1. æ•°æ®å‡†å¤‡
        self._prepare_data()
        
        # 2. åˆå§‹åŒ–é¢„æµ‹å™¨
        self._initialize_predictors()
        
        # 3. è®­ç»ƒæ¨¡å‹
        self.fit_all_models()
        
        # 4. ç”Ÿæˆé¢„æµ‹
        self.generate_all_predictions()
        
        # 5. æ€§èƒ½åˆ†æ
        self.analyze_performance()
        
        # 6. ç»¼åˆåˆ†æ
        analysis_summary = self.create_comprehensive_analysis()
        
        # 7. æ‰“å°è¯¦ç»†ç»“æœ
        self.print_detailed_results()
        
        # 8. åˆ›å»ºå¯è§†åŒ–
        self.create_advanced_visualizations()
        
        print("\nğŸ‰ åˆ†æå®Œæˆ!")
        return {
            'predictions': self.predictions,
            'performance': self.performance_summary,
            'summary': analysis_summary
        }


def main():
    """ä¸»å‡½æ•°"""
    predictor = DeepSeekPredictorModular()
    results = predictor.run_complete_analysis()
    return predictor, results


if __name__ == "__main__":
    predictor, results = main() 